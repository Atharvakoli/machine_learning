import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline


from sklearn.datasets import load_iris


iris = load_iris()


iris


print(iris['target'])


## indpependent feature
X=pd.DataFrame(iris['data'], columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])


## dependent feature
y=iris['target']


# train_test_split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=10)


## apply Decision Tree classifier
from sklearn.tree import DecisionTreeClassifier
treeClassifier= DecisionTreeClassifier(max_depth=2)


treeClassifier.fit(X_train,y_train)


## visualize the Decision Tree
from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(treeClassifier, filled=True)
plt.show()


y_pred = treeClassifier.predict(X_test)


from sklearn.metrics import confusion_matrix, classification_report


cm =  confusion_matrix(y_test,y_pred)
print(cm)
print(classification_report(y_test,y_pred))


# Post pruning for smallest dataset usually we wil do prepruning





param={
    'criterion': ['gini','entropy','log_loss'],
    'splitter': ['best', 'random'],
    'max_depth': [1,2,3,4,5],
    'max_features': ['auto','sqrt','log2'] 
}


param


from sklearn.model_selection import GridSearchCV


treemodel = DecisionTreeClassifier()


grid = GridSearchCV(treemodel, param_grid=param, cv=5, scoring='accuracy')


import warnings
warnings.filterwarnings('ignore')
print(grid.fit(X_train,y_train))


grid.best_params_


grid.best_score_


y_pred = grid.predict(X_test)
y_pred


cm =  confusion_matrix(y_test,y_pred)
print(cm)
print(classification_report(y_test,y_pred))


from sklearn.metrics import accuracy_score
score = accuracy_score(y_test,y_pred)


score





from sklearn.datasets import load_diabetes


dataset = load_diabetes()


print(dataset['DESCR'])


df_diabetes = pd.DataFrame(dataset.data, columns=['age', 'sex','bmi','bp','s1','s2','s3','s4','s5','s6'])


df_diabetes.head()


X = df_diabetes
y = dataset['target']


from sklearn.model_selection import train_test_split
X_train,X_test,y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=10)


X_train.head()


## correlation
X_train.corr()


import seaborn as sns
plt.figure(figsize=(15,10))
sns.heatmap(X_train.corr(), annot=True)
plt.show()


from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor()
regressor.fit(X_train, y_train)





param = {
    'criterion': ['squared_error', 'friedman_mse', 'absolute_error'],
    'splitter': ['best', 'random'],
    'max_depth': [1,2,3,4,5,10,15,20,25],
    'max_features': ['auto', 'sqrt', 'log2']
}


from sklearn.model_selection import GridSearchCV


regressor = DecisionTreeRegressor()


grid = GridSearchCV(regressor, param_grid=param,cv=5, scoring='neg_mean_squared_error')


print(grid.fit(X_train,y_train))


grid.best_params_


y_pred = grid.predict(X_test)


from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error


print(r2_score(y_test, y_pred))
print(mean_absolute_error(y_test, y_pred))
print(mean_squared_error(y_test, y_pred))


































































